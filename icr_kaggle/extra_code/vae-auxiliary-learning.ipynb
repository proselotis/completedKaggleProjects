{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom dataclasses import dataclass\nimport random\nimport os\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler, QuantileTransformer, RobustScaler, PowerTransformer\nfrom sklearn.feature_selection import VarianceThreshold\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, layers, Input, Model\nfrom tensorflow.experimental import numpy as tfnp\nfrom tensorflow.keras.losses import Loss\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler,OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom keras.optimizers import Adam\n\nfrom imblearn.over_sampling import SMOTE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-25T22:11:24.628475Z","iopub.execute_input":"2023-07-25T22:11:24.628901Z","iopub.status.idle":"2023-07-25T22:11:25.035575Z","shell.execute_reply.started":"2023-07-25T22:11:24.628855Z","shell.execute_reply":"2023-07-25T22:11:25.034273Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions","metadata":{}},{"cell_type":"code","source":"\n@dataclass\nclass DataHolder():\n    folds : [pd.DataFrame]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:09:29.326149Z","iopub.execute_input":"2023-07-25T22:09:29.326621Z","iopub.status.idle":"2023-07-25T22:09:29.334357Z","shell.execute_reply.started":"2023-07-25T22:09:29.326583Z","shell.execute_reply":"2023-07-25T22:09:29.332456Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\ndef balanced_log_loss(y_true, y_pred,return_all=False):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n\n    p_1 = np.clip(y_pred, 1e-15, 1 - (1e-15))\n    p_0 = 1 - p_1\n\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n\n    if return_all:\n        return (log_loss_0 + log_loss_1) / 2, log_loss_0,log_loss_1\n    return (log_loss_0 + log_loss_1) / 2\n\ndef preprocess_df(input_df: pd.DataFrame)->pd.DataFrame:\n    input_df = input_df.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'}) #?\n    output_df = input_df.copy()\n    str2int_dict = {}\n    str2int_dict['EJ'] = {'A': 1.0, 'B': 0.0}\n    for col in str2int_dict.keys():\n            output_df[col] = output_df[col].map(str2int_dict[col])\n    return output_df\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:09:29.335902Z","iopub.execute_input":"2023-07-25T22:09:29.336792Z","iopub.status.idle":"2023-07-25T22:09:29.350629Z","shell.execute_reply.started":"2023-07-25T22:09:29.336758Z","shell.execute_reply":"2023-07-25T22:09:29.349244Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Config documents","metadata":{}},{"cell_type":"code","source":"class CFG:\n    DATA_PATH = Path('/kaggle/input/icr-identify-age-related-conditions')\n\n    \n    seed = 42 #52\n    n_folds = 10 #replaced 20\n    target_col = 'Class'\n    metric = 'balanced_log_loss'","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:19.317212Z","iopub.execute_input":"2023-07-25T22:10:19.318279Z","iopub.status.idle":"2023-07-25T22:10:19.323755Z","shell.execute_reply.started":"2023-07-25T22:10:19.318241Z","shell.execute_reply":"2023-07-25T22:10:19.322468Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"seed_everything(CFG.seed)\nnp.random.seed(CFG.seed)\ntf.random.set_seed(CFG.seed)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:09:39.770802Z","iopub.execute_input":"2023-07-25T22:09:39.774935Z","iopub.status.idle":"2023-07-25T22:09:39.820197Z","shell.execute_reply.started":"2023-07-25T22:09:39.774900Z","shell.execute_reply":"2023-07-25T22:09:39.819204Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Code ","metadata":{}},{"cell_type":"markdown","source":"### Load ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(CFG.DATA_PATH / 'train.csv')\ndf_train = train_df\ngreeks_df = pd.read_csv(CFG.DATA_PATH / 'greeks.csv')\nofficial_test_df = preprocess_df(pd.read_csv(CFG.DATA_PATH / 'test.csv'))\nsub = pd.read_csv(CFG.DATA_PATH / 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:25.514713Z","iopub.execute_input":"2023-07-25T22:10:25.515260Z","iopub.status.idle":"2023-07-25T22:10:25.560486Z","shell.execute_reply.started":"2023-07-25T22:10:25.515219Z","shell.execute_reply":"2023-07-25T22:10:25.559491Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', \n                      'BD', 'BN', 'BP', 'BQ', 'BR', 'BZ',\n                      'CB', 'CC', 'CD', 'CF', 'CH', 'CL', \n                      'CR', 'CS', 'CU', 'CW',\n                      'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n                      'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU',\n                      'FC', 'FD', 'FE', 'FI', 'FL', 'FR', 'FS',\n                      'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:25.757122Z","iopub.execute_input":"2023-07-25T22:10:25.759267Z","iopub.status.idle":"2023-07-25T22:10:25.766896Z","shell.execute_reply.started":"2023-07-25T22:10:25.759216Z","shell.execute_reply":"2023-07-25T22:10:25.765317Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train['EJ'] = df_train.EJ.map({'A':0,'B':1}).astype(float)\nfeature_list_KNN = list(set(df_train.columns) - set(['Id','EJ','Class']))\nfeature_list = list(set(df_train.columns) - set(['Id','Class']))\n\nscaler = QuantileTransformer(n_quantiles=100,random_state=CFG.seed, output_distribution='normal')\ndf_train[feature_list_KNN] = scaler.fit_transform(df_train[feature_list_KNN])\ndf_train = df_train.fillna(df_train.median())","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:40.467834Z","iopub.execute_input":"2023-07-25T22:10:40.468288Z","iopub.status.idle":"2023-07-25T22:10:40.603689Z","shell.execute_reply.started":"2023-07-25T22:10:40.468253Z","shell.execute_reply":"2023-07-25T22:10:40.602533Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/1209643711.py:7: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  df_train = df_train.fillna(df_train.median())\n","output_type":"stream"}]},{"cell_type":"code","source":"encoded_df = pd.get_dummies(greeks_df, columns=['Beta','Gamma', 'Delta'])\nmerged_df = df_train.merge(encoded_df, on='Id')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:42.787009Z","iopub.execute_input":"2023-07-25T22:10:42.787415Z","iopub.status.idle":"2023-07-25T22:10:42.816152Z","shell.execute_reply.started":"2023-07-25T22:10:42.787381Z","shell.execute_reply":"2023-07-25T22:10:42.814847Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df = merged_df","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:43.058029Z","iopub.execute_input":"2023-07-25T22:10:43.059365Z","iopub.status.idle":"2023-07-25T22:10:43.064046Z","shell.execute_reply.started":"2023-07-25T22:10:43.059324Z","shell.execute_reply":"2023-07-25T22:10:43.062929Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n","metadata":{}},{"cell_type":"code","source":"train_df = greeks_df.merge(train_df,on='Id')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:49.781003Z","iopub.execute_input":"2023-07-25T22:10:49.781504Z","iopub.status.idle":"2023-07-25T22:10:49.794976Z","shell.execute_reply.started":"2023-07-25T22:10:49.781464Z","shell.execute_reply":"2023-07-25T22:10:49.794088Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def split_on_column(column):\n    train_group = [train_df[train_df['Id'].isin(greeks_df[greeks_df[column] == letter]['Id'])] for letter in greeks_df[column].unique()]\n\n    grouped_splits = [np.array_split(grouped,CFG.n_folds) for grouped in train_group]\n\n    data_holder_split = DataHolder( [pd.concat([split[i] for split in grouped_splits]) for i in range(CFG.n_folds)]\n                                   )\n    return data_holder_split","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:50.043334Z","iopub.execute_input":"2023-07-25T22:10:50.044313Z","iopub.status.idle":"2023-07-25T22:10:50.051054Z","shell.execute_reply.started":"2023-07-25T22:10:50.044275Z","shell.execute_reply":"2023-07-25T22:10:50.049887Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"positives = train_df[train_df[CFG.target_col] == 1]\nnegatives = train_df[train_df[CFG.target_col] == 0]\n\npositives_splits = np.array_split(positives, CFG.n_folds)\nnegatives_splits = np.array_split(negatives, CFG.n_folds)\n\ndata_holder_split_class = DataHolder( [pd.concat([positives_splits[i],negatives_splits[i]]) for i in range(CFG.n_folds)]\n                               )\n\ndata_holder_split_alpha = split_on_column(\"Alpha\")\ndata_holder_split_gamma = split_on_column(\"Gamma\")\n\ncv_holders = [data_holder_split_class,data_holder_split_alpha,data_holder_split_gamma]\n\n[[y.shape for y in x.folds] for x in cv_holders][2]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:10:50.673432Z","iopub.execute_input":"2023-07-25T22:10:50.674145Z","iopub.status.idle":"2023-07-25T22:10:50.769493Z","shell.execute_reply.started":"2023-07-25T22:10:50.674108Z","shell.execute_reply":"2023-07-25T22:10:50.768420Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[(65, 80),\n (64, 80),\n (64, 80),\n (63, 80),\n (62, 80),\n (61, 80),\n (61, 80),\n (61, 80),\n (58, 80),\n (58, 80)]"},"metadata":{}}]},{"cell_type":"markdown","source":"## NN adapting","metadata":{}},{"cell_type":"code","source":"def build_neutralizer(df,features,proportion):\n    \"\"\"\n\n\n    Builds neutralzied features, then trains a linear model to predict neutralized features from original\n    features and return the coeffs of that model.\n    \"\"\"\n    neutralizer = {}\n    neutralized_features = np.zeros((df.shape[0], len(features)))\n    target = df[['Class', 'bias']].values\n    for i, f in enumerate(features):\n        # obtain corrected feature\n        feature = df[f].values.reshape(-1, 1)\n        coeffs = np.linalg.lstsq(target, feature)[0]\n        neutralized_features[:, i] = (feature - (proportion * target.dot(coeffs))).squeeze()\n\n    # train model to predict corrected features\n    neutralizer = np.linalg.lstsq(df[features+['bias']].values, neutralized_features)[0]\n\n    return neutralizer\n\ndef neutralize_array(array, neutralizer):\n    neutralized_array = array.dot(neutralizer)\n    return neutralized_array","metadata":{"execution":{"iopub.status.busy":"2023-07-20T20:12:15.134943Z","iopub.execute_input":"2023-07-20T20:12:15.135388Z","iopub.status.idle":"2023-07-20T20:12:15.152304Z","shell.execute_reply.started":"2023-07-20T20:12:15.135325Z","shell.execute_reply":"2023-07-20T20:12:15.151020Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    input_shape = (len(feature_list),)\n    input_layer = Input(shape=input_shape)\n\n    # Shared layers\n    shared_layer1 = Dense(32, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_layer)\n    shared_layer2 = Dropout(.2)(shared_layer1)\n    shared_layer3 = Dense(16, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(shared_layer2)\n#     shared_layer4 = Dropout(.2)(shared_layer3)\n    shared_layer_output = Dense(8, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(shared_layer1)\n    \n    # Main branch - 'Class'\n    main_output = Dense(1, activation='sigmoid', name='main_output')(shared_layer_output)\n\n    # Additional features branch\n    additional_output = Dense(len(aux_columns), activation='sigmoid', name='additional_output')(shared_layer_output)\n\n    # Combine the outputs\n    model = Model(inputs=input_layer, outputs=[main_output, additional_output])\n    return model\ndef create_model_1_output():\n    input_shape = (len(feature_list),)\n    input_layer = Input(shape=input_shape)\n\n    # Shared layers\n    shared_layer1 = Dense(32, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_layer)\n    shared_layer2 = Dropout(.2)(shared_layer1)\n    shared_layer3 = Dense(16, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(shared_layer2)\n#     shared_layer4 = Dropout(.2)(shared_layer3)\n    shared_layer_output = Dense(8, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(shared_layer1)\n    \n    # Main branch - 'Class'\n    main_output = Dense(1, activation='sigmoid', name='main_output',bias_initializer=tf.keras.initializers.Constant(np.log(108/509)))(shared_layer_output)\n\n    # Additional features branch\n\n    # Combine the outputs\n    model = Model(inputs=input_layer, outputs=[main_output])\n    return model\n\ndef custom_loss(y_true, y_pred):\n    loss1 = K.binary_crossentropy(K.cast(y_true[0], dtype='float32'), y_pred[0])\n    loss2 = K.binary_crossentropy(K.cast(y_true[1], dtype='float32'), y_pred[1])\n    lambda_val = .6  # Adjust the value of lambda as desired\n    loss = loss1+ lambda_val * loss2\n    return loss\n\ndef pp_prob(p):\n    c0 = p[:,0].sum()\n    c1 = p[:,1:].sum()\n    new_p = p * np.array([[1/(c0 if i==0 else c1) for i in range(p.shape[1])]])\n    new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n    return np.sum(new_p[:,1:],1,keepdims=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:11:02.243994Z","iopub.execute_input":"2023-07-25T22:11:02.244400Z","iopub.status.idle":"2023-07-25T22:11:02.263220Z","shell.execute_reply.started":"2023-07-25T22:11:02.244368Z","shell.execute_reply":"2023-07-25T22:11:02.262182Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"aux_columns = ['Beta_A', 'Beta_B', 'Beta_C', 'Gamma_A', 'Gamma_B', 'Gamma_E',\n                'Gamma_F', 'Gamma_G', 'Gamma_H', 'Gamma_M', 'Gamma_N', 'Delta_A',\n                'Delta_B', 'Delta_C', 'Delta_D']","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:11:03.452254Z","iopub.execute_input":"2023-07-25T22:11:03.452628Z","iopub.status.idle":"2023-07-25T22:11:03.458187Z","shell.execute_reply.started":"2023-07-25T22:11:03.452600Z","shell.execute_reply":"2023-07-25T22:11:03.456934Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls = 1e-2, lr = 1e-3):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x0 = tf.keras.layers.BatchNormalization()(inp)\n    \n    encoder = tf.keras.layers.GaussianNoise(.4)(x0)\n    encoder = tf.keras.layers.Dense(32)(encoder)\n    encoder = tf.keras.layers.BatchNormalization()(encoder)\n    encoder = tf.keras.layers.Activation('swish')(encoder)\n\n    decoder = tf.keras.layers.Dropout(0.1)(encoder)\n    decoder = tf.keras.layers.Dense(num_columns, name = 'decoder')(decoder)\n\n    x_ae = tf.keras.layers.Dense(32)(decoder)\n    x_ae = tf.keras.layers.BatchNormalization()(x_ae)\n    x_ae = tf.keras.layers.Activation('swish')(x_ae)\n    x_ae = tf.keras.layers.Dropout(.4)(x_ae)\n\n    out_ae = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name = 'ae_action')(x_ae)\n    \n    x = tf.keras.layers.Concatenate()([x0, encoder])\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(.1)(x)\n    \n\n    x = tf.keras.layers.Dense(128)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    x = tf.keras.layers.Dropout(.4)(x)\n    \n    x = tf.keras.layers.Dense(64)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    x = tf.keras.layers.Dropout(.3)(x)\n    \n    x = tf.keras.layers.Dense(64)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    x = tf.keras.layers.Dropout(.2)(x)\n    \n    x = tf.keras.layers.Dense(32)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    x = tf.keras.layers.Dropout(.3)(x)\n    \n        \n    out = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name = 'action',bias_initializer=tf.keras.initializers.Constant(np.log(108/509)))(x)\n    \n    additional_output = Dense(len(aux_columns), activation='sigmoid', name='additional_output')(x)\n\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = [decoder, out_ae, out,additional_output])\n#     model = tf.keras.models.Model(inputs = inp, outputs = [decoder, out_ae, out])\n\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n                  loss = {'decoder': tf.keras.losses.MeanSquaredError(), \n                          'ae_action': tf.keras.losses.BinaryCrossentropy(label_smoothing = ls),\n                          'action': tf.keras.losses.BinaryCrossentropy(label_smoothing = ls),\n                          'additional_output':tf.keras.losses.CategoricalCrossentropy(label_smoothing = ls) \n                         },\n                  metrics = {'decoder': tf.keras.metrics.MeanAbsoluteError(name = 'MAE'), \n                             'ae_action': tf.keras.metrics.BinaryCrossentropy(name = 'AUC'), \n                             'action': tf.keras.metrics.BinaryCrossentropy(name = 'AUC'), \n                              'additional_output':tf.keras.losses.CategoricalCrossentropy(label_smoothing = ls) \n                            }, \n                 )\n    \n    return model\n\nparams = {'num_columns': len(feature_list), \n          'num_labels': 1, \n          'hidden_units': [32, 32, 16,32,64], \n          'dropout_rates': [0.25,0.01,0.1,0.01,.01], \n          'ls': 0.0, \n          'lr':1e-3, \n         }# (0.29453164684677857, 0.3353345524846144, 0.2537287412089428)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T23:44:25.676759Z","iopub.execute_input":"2023-07-25T23:44:25.677153Z","iopub.status.idle":"2023-07-25T23:44:25.703002Z","shell.execute_reply.started":"2023-07-25T23:44:25.677124Z","shell.execute_reply":"2023-07-25T23:44:25.701954Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy \n\ncv_strat_scores = []\nfeat_importances = []\nmodels = []\nfold_log_losses = []\nouter_y_preds = []\nfor cv_strat in tqdm(cv_holders[:2]):\n    fold_scores = []\n    temp_feat_importances = []\n    temp_models = []\n    temp_fold_log_losses = []\n    inner_y_preds = []\n    inner_histories = []\n    neural_models = {}\n    fold_losses = {}\n\n    early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15)\n\n        \n    for idx,fold_number in enumerate(range(CFG.n_folds)):\n        test_idx = idx + 1 \n        if idx == CFG.n_folds -1:\n            test_idx = 0\n        temp_data = copy.deepcopy(cv_strat.folds)\n        test = copy.deepcopy(temp_data[test_idx])\n        valid = copy.deepcopy(temp_data[idx])\n        if test_idx < idx:\n            del temp_data[idx]\n            del temp_data[test_idx]\n        else:\n            del temp_data[test_idx]\n            del temp_data[idx]\n        train = pd.concat(temp_data)\n\n################################################################################################################################################        \n\n#         temp_train = pd.concat([train,valid])\n\n#         proportion = .25\n#         temp_train['bias'] = 1.0\n#         neutralizer = build_neutralizer(temp_train, feature_list, proportion)\n#         temp_train[feature_list] = neutralize_array(temp_train[feature_list+['bias']].values, neutralizer)\n        \n#         train = temp_train.loc[train.index]\n#         valid = temp_train.loc[valid.index]\n        \n#         rows = []\n#         for idx,row in test.iterrows():\n#             rows.append(neutralize_array(np.asarray(row[feature_list].tolist() + [1.0]),neutralizer))\n\n#         test[feature_list] = rows\n        \n        \n################################################################################################################################################\n            \n\n\n        # smote = SMOTE(sampling_strategy={\"A\" : 407 * 2,\"B\" : 216 * 2, \"G\": 130*2,\"D\":61*2},random_state=CFG.seed)\n#         MULTIPLIER = 2\n#         d = {col : train[train['Gamma'] == col].shape[0] * MULTIPLIER for col in train['Gamma'].value_counts().index.tolist()}\n#         smote = SMOTE(sampling_strategy=d,random_state=CFG.seed,k_neighbors=train['Gamma'].value_counts().min() - 1)\n#         X_smote, y_smote = smote.fit_resample(train[feature_list], train['Gamma'])\n\n#         train = pd.concat([X_smote,y_smote],1)\n\n#         train['Class'] = np.where(train['Gamma'].isin([\"M\",\"N\"]), 1, 0)\n#         train['Alpha_x'] = -1\n#         train['Alpha_x'] = np.where(train['Gamma'].isin(['A','B']), \"G\", train['Alpha_x'])\n#         train['Alpha_x'] = np.where(train['Gamma'].isin(['E','F']), \"D\", train['Alpha_x'])\n#         train['Alpha_x'] = np.where(train['Gamma'].isin(['G','H']), \"B\", train['Alpha_x'])\n#         train['Alpha_x'] = np.where(train['Gamma'].isin(['M','N']), \"A\", train['Alpha_x'])\n\n#         encoded_df = pd.get_dummies(train, columns=['Gamma'])\n#         train = train.merge(encoded_df)\n        \n#         smote = SMOTE(sampling_strategy=1,random_state=CFG.seed)\n#         X_smote, y_smote = smote.fit_resample(train[feature_list], train['Class'])\n#         train = pd.concat([X_smote,y_smote],1)\n\n#         Separate positive and negative samples\n        positive_samples = train[train['Class'] == 1]\n        negative_samples = train[train['Class'] == 0]\n\n        # Upsample positive samples to match the size of negative samples\n        upsampled_positive_samples = positive_samples.sample(n=int(len(negative_samples)//2.0), replace=True)\n\n        # Combine the upsampled positive samples with the negative samples\n        balanced_data = pd.concat([negative_samples, upsampled_positive_samples])\n\n        # Shuffle the rows in the balanced DataFrame\n        balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n\n        train = balanced_data\n        \n#################################################################################################################################################\n        BATCH_SIZE = 128\n\n\n\n        train_ds = tf.data.Dataset.from_tensor_slices(  (train[feature_list].to_numpy(),  {\"action\": train['Class'].to_numpy(),\"additional_output\":  train[aux_columns].to_numpy()} ) ).batch(BATCH_SIZE)\n        valid_ds = tf.data.Dataset.from_tensor_slices(  (valid[feature_list].to_numpy(),  {\"action\": valid['Class'].to_numpy(), \"additional_output\": valid[aux_columns].to_numpy()} ) ).batch(BATCH_SIZE)\n        \n        \n        \n        test_x_ds = tf.data.Dataset.from_tensor_slices(test[feature_list].to_numpy()).batch(BATCH_SIZE)\n\n        model = create_ae_mlp(**params)\n        ckp = ModelCheckpoint(\".\", monitor = 'val_action_loss', verbose = 0, \n                              save_best_only = True, save_weights_only = True, mode = 'min')\n        es = EarlyStopping(monitor = 'val_action_loss',\n#                            monitor = ['val_action_loss','val_loss'],\n                           patience = 7, mode = 'min', \n                           baseline = None, restore_best_weights = True, verbose = 0)\n        history = model.fit(train_ds, validation_data = valid_ds, \n                            epochs = 100, batch_size = BATCH_SIZE, callbacks = [ckp, es], verbose = 0)\n        \n        output = model.predict(test_x_ds)\n        ae_pred = output[1]\n        y_pred_pre = output[2]\n\n        y_pred = pp_prob(np.append(1 - y_pred_pre,y_pred_pre,1))\n        ae_pred = pp_prob(np.append(1 - ae_pred,ae_pred,1))\n\n################################################################################################################################################\n       \n        score,log_loss_0,log_loss_1 = balanced_log_loss(test['Class'], np.ravel(y_pred),return_all=True)\n        print(f\"{idx}:\",balanced_log_loss(test['Class'], np.ravel(y_pred),return_all=True))\n\n        fold_scores.append(score)\n        temp_fold_log_losses.append([log_loss_0,log_loss_1])\n        inner_y_preds.append({test.index[i] : y_pred[i] for i in range(len(test))})\n        \n    cv_strat_scores.append(fold_scores)\n    outer_y_preds.append(inner_y_preds)\n    fold_log_losses.append(temp_fold_log_losses)\n\n\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T23:44:31.024014Z","iopub.execute_input":"2023-07-25T23:44:31.024396Z","iopub.status.idle":"2023-07-25T23:50:05.940911Z","shell.execute_reply.started":"2023-07-25T23:44:31.024359Z","shell.execute_reply":"2023-07-25T23:50:05.939791Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stderr","text":"  0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 286ms/step\n0: (0.20253755663644937, 0.25443758969608693, 0.15063752357681182)\n1/1 [==============================] - 0s 284ms/step\n1: (0.2909369095180721, 0.4221985642459008, 0.1596752547902434)\n1/1 [==============================] - 0s 302ms/step\n2: (0.2727189820480216, 0.4135403323812609, 0.13189763171478228)\n1/1 [==============================] - 0s 286ms/step\n3: (0.35972167416840495, 0.36587702574449427, 0.3535663225923157)\n1/1 [==============================] - 0s 278ms/step\n4: (0.38157698125817807, 0.42517861506171123, 0.3379753474546449)\n1/1 [==============================] - 0s 418ms/step\n5: (0.3932764762179827, 0.47243367260159413, 0.31411927983437116)\n1/1 [==============================] - 0s 320ms/step\n6: (0.39706086743420754, 0.46415406952204347, 0.3299676653463716)\n1/1 [==============================] - 0s 284ms/step\n7: (0.499148847857291, 0.48789253588641257, 0.5104051598281695)\n1/1 [==============================] - 0s 290ms/step\n8: (0.3033196955679868, 0.392536044460256, 0.2141033466757177)\n1/1 [==============================] - 0s 290ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 1/2 [03:08<03:08, 188.32s/it]","output_type":"stream"},{"name":"stdout","text":"9: (0.28622975038645615, 0.1867120330034812, 0.38574746776943114)\n1/1 [==============================] - 0s 281ms/step\n0: (0.21918006250529137, 0.26256786906319846, 0.1757922559473843)\n1/1 [==============================] - 0s 286ms/step\n1: (0.23634310319090407, 0.3089418955618254, 0.16374431081998278)\n1/1 [==============================] - 0s 288ms/step\n2: (0.32994654581171323, 0.2551186842426635, 0.404774407380763)\n1/1 [==============================] - 0s 302ms/step\n3: (0.4481030987425062, 0.38493383154697675, 0.5112723659380356)\n1/1 [==============================] - 0s 292ms/step\n4: (0.38838818662372543, 0.5628314961277487, 0.21394487711970206)\n1/1 [==============================] - 0s 293ms/step\n5: (0.44996172155694864, 0.5013288769410739, 0.3985945661728234)\n1/1 [==============================] - 0s 303ms/step\n6: (0.4673892635835877, 0.5624067345671457, 0.3723717926000296)\n1/1 [==============================] - 0s 349ms/step\n7: (0.5054713455124515, 0.45357643532504377, 0.5573662556998592)\n1/1 [==============================] - 0s 283ms/step\n8: (0.30350464436539676, 0.4075962215880679, 0.19941306714272558)\n1/1 [==============================] - 0s 295ms/step\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [05:34<00:00, 167.44s/it]","output_type":"stream"},{"name":"stdout","text":"9: (0.3655296495244337, 0.22085123590233297, 0.5102080631465344)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import ChainMap\n\ncv_0_preds = dict(ChainMap(*outer_y_preds[0]))\ncv_1_preds = dict(ChainMap(*outer_y_preds[1]))\n# cv_2_preds = dict(ChainMap(*outer_y_preds[2]))\n\nimport plotly.express as px\n\nbase = pd.DataFrame(cv_0_preds,index=['prediction_0']).T.sort_index().join(pd.DataFrame(cv_1_preds,index=['prediction_1']).T.sort_index())\nbase['weighted_prediction'] = base[['prediction_0','prediction_1']].mean(axis=1)\n\nbase['GT'] = train_df['Class']\n\n\npx.scatter(base,\"weighted_prediction\",color=\"GT\",color_continuous_scale=\"picnic\",)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T23:50:05.943563Z","iopub.execute_input":"2023-07-25T23:50:05.944053Z","iopub.status.idle":"2023-07-25T23:50:06.066825Z","shell.execute_reply.started":"2023-07-25T23:50:05.944010Z","shell.execute_reply":"2023-07-25T23:50:06.065566Z"},"trusted":true},"execution_count":83,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"1ef16d40-0bf5-4754-9a92-ee7115847ec6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1ef16d40-0bf5-4754-9a92-ee7115847ec6\")) {                    Plotly.newPlot(                        \"1ef16d40-0bf5-4754-9a92-ee7115847ec6\",                        [{\"hovertemplate\":\"weighted_prediction=%{x}<br>index=%{y}<br>GT=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[1,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,1,0,1,1,0,0,1,0,1,1,0,0,0,0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"x\":[0.7810806937024322,0.007363562094424318,0.17370233121018508,0.012470676342773978,0.9710531876029478,0.010618779350168663,0.012998037987380098,0.01940067824436851,0.04701680447318746,0.029936554489407186,0.9637199354529071,0.09338892866521858,0.9128265919160725,0.9816291061150124,0.22343856693133013,0.23098265529486525,0.12292731872864682,0.08891323804542092,0.10824585466533133,0.023535844589769546,0.027060321185335395,0.19813986858701232,0.05107394348597301,0.005399114410709144,0.2276583028578898,0.09040255650069479,0.7895678511528865,0.013782221265581512,0.05202474424410429,0.5641167697127463,0.029093484381899955,0.8733632070439328,0.01869152792541485,0.09339665235726247,0.08067751658582673,0.01288819005711063,0.765644124521941,0.04307825410448821,0.010174383922194996,0.12167826050746829,0.011375943535043388,0.9990032753474438,0.0057791528533872386,0.07869785260001644,0.06503098210139446,0.04425506918784227,0.0242311850338067,0.009273771745014956,0.044591065184534144,0.994974265332762,0.013297175378703258,0.46364377805405504,0.2618945018432501,0.02883009847130428,0.05951729674490757,0.14106821548333096,0.1344967377188196,0.06419426230469111,0.4171864119747748,0.049649922925084564,0.18263843925834353,0.19573115314535167,0.12332838805355581,0.2576337287222767,0.026623685928606654,0.041413886481564716,0.39782080808917325,0.5304184457649785,0.014170123487050643,0.25208750324502727,0.08195700549717924,0.12358519953945346,0.23813527198941806,0.31065700954933495,0.07834244682197039,0.9965727162419745,0.9970647410433878,0.08412910066048093,0.13799012763071447,0.9995225357782194,0.29092052981573696,0.0957802050598098,0.0575697065704259,0.1367478722882552,0.019227107698587584,0.03254446434171351,0.03997654758042168,0.11425776039740379,0.9938100979428676,0.21003975163058775,0.06813472140133914,0.4556039563997271,0.23571376824574075,0.6221860011590905,0.08876537516946079,0.9082322223356945,0.5949106087438709,0.32111269425722444,0.07934155313834185,0.207880361849503,0.0876949656492964,0.42701462996883,0.9075424425600301,0.027038728043484277,0.11357322961001395,0.143676483045167,0.05919881594906322,0.13532766070622382,0.08627961266826834,0.9296683743207463,0.6362019324852783,0.17136112494480868,0.1457112757320463,0.752927959201271,0.06760129612393156,0.07222875929888921,0.08791153428777465,0.08523615905010684,0.9922894114398261,0.043109045208024804,0.19728722843716007,0.7530819016158559,0.020357792935958102,0.47374522022983034,0.05110774686224624,0.00789762416202821,0.004391538219328591,0.9502003096128804,0.007474476884339019,0.3714878063632948,0.34541869687985416,0.9786454976662924,0.3575312227084055,0.0017711325647479254,0.9774721685714893,0.2341678250458142,0.22834663300135377,0.1524412285477516,0.011673485118803768,0.16858641813775846,0.41675934414327054,0.31398373177156785,0.21087445902323998,0.1895913950987348,0.01459912692437247,0.7514617775760557,0.7987923896585494,0.2196818174586606,0.694130692221955,0.25105509695655337,0.6192780320304313,0.16864738367885518,0.003769642518118822,0.006273077154212716,0.0017053385332717638,0.9197610350985737,0.06383215403095727,0.0026145707933520907,0.8317494097879632,0.1189469890172865,0.9197893882900416,0.037933081831098565,0.9654928369999953,0.4339340586870575,0.44867304093591137,0.9922567350197158,0.003650842169880107,0.9601092095732631,0.5264877986521671,0.1455026756860456,0.443426944631366,0.6081493969464716,0.11025138160860257,0.06539167469625913,0.06428701100787222,0.006180609846959763,0.007893810618466762,0.011188269815905538,0.6231952675513356,0.07788850197821998,0.010122230541278407,0.895205797067835,0.08116883091208453,0.21859959186798333,0.0386863522603876,0.18538904326718073,0.7595028377548018,0.04137968810947991,0.03221461216326655,0.9349187377832642,0.5255895954094345,0.7254613108419968,0.023485402445607515,0.8093059941675013,0.9636065609664584,0.45057421686034077,0.2500416930772219,0.24703384151783436,0.1299004179351943,0.29562626872984865,0.027743109741021413,0.03247965694270929,0.7195321391109996,0.7236759700156761,0.014482674266525268,0.03366608659093375,0.055406986242917,0.0413981446198339,0.04868963984308512,0.08590129541870255,0.04319020513762776,0.07323068604171185,0.1210009763033289,0.04247557067501154,0.03363372590386731,0.19504790954296405,0.05926102019252652,0.350911778157183,0.6311167248677302,0.041492590612588934,0.15459156106193084,0.020068467924032572,0.05662559939980404,0.0187875251173159,0.8160329330211277,0.4736356034906058,0.04496032582690487,0.09531466235410735,0.07575817405720597,0.9059293668761338,0.04662925566638459,0.12170119679613634,0.8376501962232605,0.13323926112143689,0.06816319205619957,0.12369672809315896,0.09301964224630341,0.10428355471160146,0.6041202045595166,0.14391801072593335,0.033136160137654525,0.44273977741485415,0.5686424673115293,0.010136480157433965,0.03709804455379111,0.25184472529985596,0.854790099359048,0.6299683950180673,0.19145746581853346,0.9934668553391459,0.00517516595304153,0.9184276782591314,0.03416420823470217,0.015993415565233662,0.004676632049069714,0.15407740759210198,0.9867779252022761,0.003120141330104947,0.9988110867939459,0.9981324336845563,0.12334541186073916,0.9610051324896487,0.9492235392998849,0.04411782139237076,0.08478635145978286,0.9775075519503047,0.016462571124672767,0.22712341336018457,0.8944750833205697,0.0039952705301111524,0.005931838898675827,0.06868179942196305,0.06735216336196496,0.16074916845155968,0.9739999210141654,0.48905208968697145,0.3828513408183899,0.14726213904746863,0.14464790018120152,0.011419544579646026,0.8491936872532502,0.01903658048201414,0.9794934890705285,0.02202793699045641,0.011816267074613999,0.003994729853081556,0.1263875424731407,0.18500486105540284,0.9990677544770177,0.027399969757031382,0.9240013017251614,0.009069397646839391,0.9329374306019937,0.06702397845734231,0.7351837905417021,0.6760162922690003,0.025980124620546004,0.2577138994759917,0.01799629122220705,0.7052357510360721,0.9309026700197502,0.5378234552345178,0.004330863251169635,0.008954485062333407,0.9364541278463234,0.004159312654421194,0.036960896899505054,0.604434873559236,0.6891497209238948,0.00871721503710951,0.002519340949128423,0.1590511733117136,0.023977558636075084,0.1345281097815146,0.1170833223877944,0.07656969820448589,0.09248084222017061,0.03601451261930409,0.4027931187186697,0.02440441257205366,0.29942267408305395,0.052448245111703075,0.49478447792813385,0.3388952568650059,0.888556425414935,0.1535253447092508,0.571921208624802,0.17112310259961402,0.036766727858683415,0.041748877898223014,0.9481157752321407,0.25849236506007367,0.09970408679253877,0.06001949766269095,0.1930417097368272,0.04752599432739252,0.6711884759458959,0.755825725140906,0.8595886513207722,0.10746149603943736,0.8198346242213912,0.08559275924875769,0.16429970703840538,0.0679300573613831,0.9526587592296036,0.6400107241761077,0.23565679413485013,0.1699669470134595,0.9238706362047084,0.18963612317259887,0.07063487621529715,0.10830540545744642,0.2852753416134295,0.35818014243559015,0.11292532023029139,0.14552445687087456,0.9724525530359956,0.9735860788849049,0.3219847524711139,0.054775649384210603,0.9466296882568788,0.11126386817218908,0.7721489345516022,0.42068034615554284,0.036976437515906554,0.09993851227225248,0.21709859911520812,0.42881425705370557,0.9926421111373773,0.05224042844050917,0.11036943242566319,0.732964326718401,0.8190875220418257,0.05131837085855398,0.6383747993408639,0.4122139296983723,0.2566447947558803,0.6415398999956052,0.9575044260170458,0.07638919847862898,0.5890866346279137,0.05801459229557576,0.4802708957059585,0.39391890916457517,0.05024741213532896,0.5264193948109691,0.9042621890911743,0.8021633580129441,0.48504575625959595,0.6556552476561697,0.3835912570501984,0.5013931944834963,0.29339075919023105,0.37828764356648475,0.27901198677552747,0.2191403993367279,0.25513166209886273,0.16315870408073768,0.1381588710193778,0.1247386180733636,0.28688218387342657,0.22108960072335762,0.25767204180854464,0.05166280398833882,0.2264366350117094,0.041925852329882086,0.9619212598705468,0.04569557128489774,0.5502922773891743,0.5983117849565001,0.305318462117118,0.008605386483167232,0.8582823383718967,0.5519194930196369,0.07526733302645648,0.8817639484575279,0.030988830738443295,0.4634488383710594,0.6766217874106024,0.7111313881111299,0.002407476010586725,0.4451279715616362,0.3003985390848323,0.8120545628984958,0.3586785141080545,0.8277660418659019,0.14964272318659053,0.27753779929384537,0.37813715297371997,0.016425029865775657,0.3154901413411425,0.032501390189626,0.002605835655738246,0.8956159956526144,0.3135342864135585,0.49146823014402274,0.6569815433370152,0.1318473096502637,0.11596539638204019,0.6659271728802189,0.10315763916960483,0.1360054929408028,0.08328897008092481,0.12394657042126622,0.1543686991806511,0.2963060474304843,0.2936314145009584,0.34640400632038437,0.2629464245689588,0.20780071322370636,0.132408374060746,0.3236823002002863,0.4218984857395952,0.20083148454070543,0.14659289882415247,0.6043118136436572,0.23319555789335156,0.6418793396899285,0.35115847445735365,0.5320355331147261,0.3141779568187622,0.4930325680529499,0.8157034660154632,0.26128422194956424,0.3292647851114557,0.11432863221027867,0.8401213312661941,0.5968205239428472,0.797074838076439,0.29451305113705895,0.9299644630477255,0.7952511154565176,0.21340003913555175,0.1229145778655554,0.17576573001145615,0.39004494171780063,0.2851962594927268,0.15098463350966662,0.22137263804079924,0.7656313367004642,0.3900167837182185,0.6022564885651225,0.3044871641563538,0.3207148192934557,0.7501648343456636,0.23802234431978098,0.7318352378708387,0.7047261609232891,0.6260628497948455,0.24562905672106367,0.9118965105004017,0.5818298966233629,0.28625498304174657,0.9273504146950065,0.9257444084958739,0.23038419587207065,0.19246444358083487,0.08139266282548115,0.6892093829909915,0.08149098368561727,0.3891133976962201,0.5994549699250531,0.029026925975252846,0.8397327799898032,0.5732398932399996,0.17363569107005844,0.5575925143604524,0.19779182369093531,0.29578596809701907,0.08480829690945088,0.07423386289511963,0.9591360269589152,0.12202572794266642,0.6776745195307688,0.34199316961994397,0.35226189428150684,0.759858121683234,0.10691666522554694,0.7104911774400018,0.2900651022588364,0.46684872806295186,0.3050371827804491,0.18497745622353645,0.8852830881219514,0.07804979598410267,0.07384968928060243,0.718017483344702,0.6053874668556309,0.4827258475870165,0.11805748880723148,0.9677427713842188,0.09438266095838033,0.2246369101136117,0.24244633382800518,0.10655269975851454,0.14250982094024392,0.8595232828130983,0.4831516050662602,0.6074816262334667,0.37163382715165544,0.2379082594207799,0.16697622183206823,0.1416342983931323,0.273403687193697,0.247847761403514,0.476244199681529,0.8070929332381738,0.1275254939682196,0.8975518382294062,0.34938160555305936,0.029026142852729427,0.037291968953663705,0.5612330875264833,0.8497592019185515,0.12158867775734522,0.8499411979570581,0.6816535446601666,0.12088311505166367,0.19517550063799788,0.7717609938120524,0.09075430290187778,0.058656852902444934,0.08318525806965402,0.9228889361151428,0.9020894099627124,0.1663255912094348,0.1873258421243126,0.705955100338244,0.1274718871108164,0.10602833367394149,0.1879804396977904,0.28130498980449903,0.032775704078825095,0.10517223546556151,0.1817169392395132,0.22616788787342984,0.7208679538930038,0.04649687931915711,0.3772843074999795,0.04618315536569933,0.8371948767457811,0.46833213087274994,0.41761433477746135,0.04868298145974241,0.24143705039514854,0.8767276851767734,0.8151550203919349,0.2895287223392037,0.957407455613642,0.5565226688352839,0.24699309685987658,0.04788502629835942,0.5952444899334334,0.14900093538355857,0.06910256474205682,0.20965114347756586,0.28431516375869786,0.23877691017471803,0.04458523189793619,0.16697430200871316,0.3410760145440161,0.03759047608000683,0.37290304807071906,0.607513003756441,0.1026189911647193,0.23540281236703234,0.6987767399170703,0.03817801781041069,0.749776905767032,0.6462921251031235,0.5357110192625509,0.023826027687603675,0.29857587803704255,0.7853884188054685,0.039718887381034435,0.33664930807749216,0.0903369446321969],\"xaxis\":\"x\",\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"weighted_prediction\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"GT\"}},\"colorscale\":[[0.0,\"rgb(0,0,255)\"],[0.1,\"rgb(51,153,255)\"],[0.2,\"rgb(102,204,255)\"],[0.3,\"rgb(153,204,255)\"],[0.4,\"rgb(204,204,255)\"],[0.5,\"rgb(255,255,255)\"],[0.6,\"rgb(255,204,255)\"],[0.7,\"rgb(255,153,255)\"],[0.8,\"rgb(255,102,204)\"],[0.9,\"rgb(255,102,102)\"],[1.0,\"rgb(255,0,0)\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('1ef16d40-0bf5-4754-9a92-ee7115847ec6');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"frame_scores = pd.DataFrame(cv_strat_scores,columns=[f\"fold_{i}\" for i in range(CFG.n_folds)],index=['Class','Alpha'])\nlog_loss_mean_details = pd.DataFrame(np.mean(fold_log_losses,axis=1),columns=[\"mean_log_loss0\",\"mean_log_loss1\" ],index=['Class','Alpha'])\nlog_loss_std_details = pd.DataFrame(np.std(fold_log_losses,axis=1),columns=[\"std_log_loss0\",\"std_log_loss1\" ],index=['Class','Alpha'])\ndisplay(frame_scores)\ndisplay(frame_scores.agg([np.mean,np.std],axis=1).join(log_loss_mean_details).join(log_loss_std_details)[['mean','std','mean_log_loss0','std_log_loss0','mean_log_loss1','std_log_loss1']])\nframe_scores.mean().mean()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T23:50:19.155960Z","iopub.execute_input":"2023-07-25T23:50:19.156380Z","iopub.status.idle":"2023-07-25T23:50:19.199841Z","shell.execute_reply.started":"2023-07-25T23:50:19.156347Z","shell.execute_reply":"2023-07-25T23:50:19.198680Z"},"trusted":true},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":"         fold_0    fold_1    fold_2    fold_3    fold_4    fold_5    fold_6  \\\nClass  0.202538  0.290937  0.272719  0.359722  0.381577  0.393276  0.397061   \nAlpha  0.219180  0.236343  0.329947  0.448103  0.388388  0.449962  0.467389   \n\n         fold_7    fold_8   fold_9  \nClass  0.499149  0.303320  0.28623  \nAlpha  0.505471  0.303505  0.36553  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold_0</th>\n      <th>fold_1</th>\n      <th>fold_2</th>\n      <th>fold_3</th>\n      <th>fold_4</th>\n      <th>fold_5</th>\n      <th>fold_6</th>\n      <th>fold_7</th>\n      <th>fold_8</th>\n      <th>fold_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Class</th>\n      <td>0.202538</td>\n      <td>0.290937</td>\n      <td>0.272719</td>\n      <td>0.359722</td>\n      <td>0.381577</td>\n      <td>0.393276</td>\n      <td>0.397061</td>\n      <td>0.499149</td>\n      <td>0.303320</td>\n      <td>0.28623</td>\n    </tr>\n    <tr>\n      <th>Alpha</th>\n      <td>0.219180</td>\n      <td>0.236343</td>\n      <td>0.329947</td>\n      <td>0.448103</td>\n      <td>0.388388</td>\n      <td>0.449962</td>\n      <td>0.467389</td>\n      <td>0.505471</td>\n      <td>0.303505</td>\n      <td>0.36553</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           mean       std  mean_log_loss0  std_log_loss0  mean_log_loss1  \\\nClass  0.338653  0.084056        0.388496       0.092182        0.288809   \nAlpha  0.371382  0.098492        0.392015       0.120805        0.350748   \n\n       std_log_loss1  \nClass       0.115506  \nAlpha       0.143791  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean_log_loss0</th>\n      <th>std_log_loss0</th>\n      <th>mean_log_loss1</th>\n      <th>std_log_loss1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Class</th>\n      <td>0.338653</td>\n      <td>0.084056</td>\n      <td>0.388496</td>\n      <td>0.092182</td>\n      <td>0.288809</td>\n      <td>0.115506</td>\n    </tr>\n    <tr>\n      <th>Alpha</th>\n      <td>0.371382</td>\n      <td>0.098492</td>\n      <td>0.392015</td>\n      <td>0.120805</td>\n      <td>0.350748</td>\n      <td>0.143791</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"0.35501726812550044"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}